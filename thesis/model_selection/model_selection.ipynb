{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350819d2-272c-4bfe-95e0-5ed245c53969",
   "metadata": {},
   "source": [
    "# AHP + TOPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02f43e5e-f5bd-4aad-94a8-06ec8c9b1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b656ac-f5bd-44ed-b0a3-93a493c7b59c",
   "metadata": {},
   "source": [
    "### 1. CRITERIA & CANDIDATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74bfb9af-b460-4959-8f25-ca25f81f13da",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = [\n",
    "    \"RTV‑Bench (Acc)\", \"Temporal Type\", \n",
    "    \"Structured Out\", \"Inference Cost\", \"Hardware Req\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3aacf6-4250-47f3-b97f-f43737cc1e0d",
   "metadata": {},
   "source": [
    "### Benefit: 1, Cost: -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d2b552e-6276-4a89-869b-410a8435a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_benefit = [1, -1, 1, -1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60665f57-70e4-4a64-b7c2-d917547d7dfc",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "1. RTV‑Bench https://arxiv.org/abs/2505.02064\n",
    "2. Duration: seconds (but GPT-4o is 1 frame)\n",
    "3. Temp Type: Below\n",
    "4. Structured: 1 (Prompt), 2 (Strict JSON Mode)\n",
    "5. Inference Cost: $/million tokens (input + output)\n",
    "6. HW: 1 (Low/API) to 10 (High/Multi-GPU Cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9997b-a8e8-4110-85a2-ca74d3ddc7d6",
   "metadata": {},
   "source": [
    "| Rank          | Temporal Representation            | Model         | Notes                                                            |\n",
    "| ------------- | ---------------------------------- | --------------------- | ---------------------------------------------------------|\n",
    "| **1 (Best)**  | Absolute time encoding             | Qwen2.5‑VL            | Frame-level timestamp allows precise start/end detection |\n",
    "| **2**         | Spatial‑Temporal Convolution (STC) | VideoLLaMA2           | Good for motion/action patterns, slight temporal smoothing|\n",
    "| **3**         | Composite frame representation     | InternLM‑XComposer2.5 | Dense frames preserve granularity, computationally heavy |\n",
    "| **4**         | Frame sequence representation      | LLaVA‑Video           | Preserves order but may downsample                       |\n",
    "| **5**         | Compact vision tokens              | VideoLLaMA3           | Efficient for long videos, poor for very short actions |\n",
    "| **6**         | Proprietary transformer encoding   | Gemini 2.0 Flash      | Unknown internal representation; likely good general temporal understanding, may miss precise short actions |\n",
    "| **7 (Worst)** | N/A                                | GPT‑4o                | Cannot handle video → cannot detect temporal actions     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "29e7bde5-76ed-4be0-8b6c-b0423f57d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # Proprietary Models (API-centric)\n",
    "    \"OpenAI GPT-4o\":         [50.0, 7, 2, 20, 1], \n",
    "    \"Gemini 2.5\":      [42.0, 6, 2, 14, 1],\n",
    "    \n",
    "    # Open-Source SOTA\n",
    "    \"Qwen2.5-VL\":            [40.4, 1, 1, 0.0, 6], # 7B: 16GB VRAM (RTX 4090/A4000)\n",
    "    \"InternLM-XComposer2.5\": [47.3, 3, 1, 0.0, 7], # 7B but dense frames: 24GB VRAM (RTX 4090/A5000)\n",
    "    \n",
    "    # Specialized/Physical Reasoning\n",
    "    # \"NVIDIA Cosmos Reason 1\":[-, 60, 3, 2, 1.2, 8], \n",
    "    # \"NVIDIA Cosmos Reason 2\":[-, 60, 3, 2, 1.5, 9], \n",
    "    \n",
    "    # Efficient Candidates\n",
    "    \"LLaVA-Video\":           [34.9, 4, 1, 0.0, 6], # 7B: 16GB VRAM\n",
    "    \"VideoLLaMA2\":           [39.6, 2, 1, 0.0, 6], # 7B: 16GB VRAM\n",
    "    \"VideoLLaMA3\":           [36.4, 5, 1, 0.0, 5], # 8B but optimized tokens: 12GB VRAM (RTX 3090)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6b945bd-1377-4d04-8255-b4b96aaa443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ahp_weights():\n",
    "    # 6x6 Comparison Matrix (n=6)\n",
    "    # Order: [RTV, Duration, TempType, StructOut, Cost, HW]\n",
    "    n = len(criteria)\n",
    "    A = np.ones((n, n))  # Initialize with all 1s\n",
    "    np.fill_diagonal(A, 1)\n",
    "\n",
    "    # Pairwise Judgments\n",
    "    A[0, 2] = 2; A[0, 4] = 3;\n",
    "    A[2, 1] = 4; A[2, 3] = 2;\n",
    "\n",
    "    # Fill reciprocals\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            A[j, i] = 1 / A[i, j]\n",
    "\n",
    "    # Priority Vector (Weights)\n",
    "    weights = (A / A.sum(axis=0)).mean(axis=1)\n",
    "\n",
    "    # Consistency Check\n",
    "    eig_val = np.linalg.eig(A)[0].max().real\n",
    "    ci = (eig_val - n) / (n - 1)\n",
    "    ri = 1.12\n",
    "    cr = ci / ri\n",
    "\n",
    "    return weights, cr\n",
    "\n",
    "def run_topsis(data, weights, is_benefit):\n",
    "    # Vector Normalization\n",
    "    norm_data = data / np.sqrt((data**2).sum(axis=0))\n",
    "    weighted_norm = norm_data * weights\n",
    "    \n",
    "    # Determine Ideal Best (PIS) and Ideal Worst (NIS)\n",
    "    pis = [weighted_norm[:, j].max() if is_benefit[j] == 1 else weighted_norm[:, j].min() for j in range(len(weights))]\n",
    "    nis = [weighted_norm[:, j].min() if is_benefit[j] == 1 else weighted_norm[:, j].max() for j in range(len(weights))]\n",
    "    \n",
    "    # Euclidean Distances\n",
    "    s_plus = np.sqrt(((weighted_norm - pis)**2).sum(axis=1))\n",
    "    s_minus = np.sqrt(((weighted_norm - nis)**2).sum(axis=1))\n",
    "    \n",
    "    # Final TOPSIS Score\n",
    "    return s_minus / (s_plus + s_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb2473bd-d030-4d44-8b5b-419e24577cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTION\n",
    "weights, cr = calculate_ahp_weights()\n",
    "model_names = list(models.keys())\n",
    "data_matrix = np.array(list(models.values()))\n",
    "scores = run_topsis(data_matrix, weights, is_benefit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1de84f05-affb-4b43-b16f-2be2e0da4605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AHP RESULTS ---\n",
      "Consistency Ratio (CR): 0.0544 (Acceptable if < 0.1)\n",
      "Weights per Criteria:\n",
      "  RTV‑Bench (Acc): 28.39%\n",
      "  Temporal Type: 19.04%\n",
      "  Structured Out: 19.77%\n",
      "  Inference Cost: 17.23%\n",
      "  Hardware Req: 15.57%\n"
     ]
    }
   ],
   "source": [
    "# Output for LaTeX\n",
    "print(f\"--- AHP RESULTS ---\")\n",
    "print(f\"Consistency Ratio (CR): {cr:.4f} (Acceptable if < 0.1)\")\n",
    "print(\"Weights per Criteria:\")\n",
    "for c, w in zip(criteria, weights):\n",
    "    print(f\"  {c}: {w:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fc91b23-ce6e-4ac8-9aa6-3782575c7ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL TOPSIS RANKING ---\n",
      "1. Qwen2.5-VL             | Score: 0.6742\n",
      "2. VideoLLaMA2            | Score: 0.6570\n",
      "3. InternLM-XComposer2.5  | Score: 0.6276\n",
      "4. LLaVA-Video            | Score: 0.5978\n",
      "5. VideoLLaMA3            | Score: 0.5889\n",
      "6. Gemini 2.5             | Score: 0.4382\n",
      "7. OpenAI GPT-4o          | Score: 0.3600\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- FINAL TOPSIS RANKING ---\")\n",
    "ranked_results = sorted(zip(model_names, scores), key=lambda x: x[1], reverse=True)\n",
    "for i, (name, score) in enumerate(ranked_results, 1):\n",
    "    print(f\"{i}. {name:22} | Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c143c12-33ea-43a7-92fe-bf59dbf853e5",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cefae25a-1d62-4eae-9fed-e26034389a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis_weights(base_weights, data_matrix, model_names, is_benefit, variation_pct=0.2):\n",
    "    results = []\n",
    "    base_scores = run_topsis(data_matrix, base_weights, is_benefit)\n",
    "    base_ranking = [model_names[i] for i in np.argsort(base_scores)[::-1]]\n",
    "    \n",
    "    for criterion_idx in range(len(base_weights)):\n",
    "        for multiplier in [1 - variation_pct, 1 + variation_pct]:\n",
    "            # Create modified weights\n",
    "            modified_weights = base_weights.copy()\n",
    "            modified_weights[criterion_idx] *= multiplier\n",
    "            # Re-normalize to sum to 1\n",
    "            modified_weights /= modified_weights.sum()\n",
    "            \n",
    "            # Run TOPSIS with modified weights\n",
    "            new_scores = run_topsis(data_matrix, modified_weights, is_benefit)\n",
    "            new_ranking = [model_names[i] for i in np.argsort(new_scores)[::-1]]\n",
    "            \n",
    "            # Calculate rank correlation (Spearman)\n",
    "            from scipy.stats import spearmanr\n",
    "            rank_corr = spearmanr([base_ranking.index(m) for m in model_names],\n",
    "                                  [new_ranking.index(m) for m in model_names])[0]\n",
    "            \n",
    "            results.append({\n",
    "                'Criterion': criteria[criterion_idx],\n",
    "                'Change': f\"{multiplier:.1%}\",\n",
    "                'Top_3': new_ranking[:3],\n",
    "                'Spearman_ρ': rank_corr,\n",
    "                'Top_Model_Changed': new_ranking[0] != base_ranking[0]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a53859c-87b2-44d3-b5b2-f5cc97d1dbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Criterion  Change                                             Top_3  \\\n",
      "0  RTV‑Bench (Acc)   80.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "1  RTV‑Bench (Acc)  120.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "2    Temporal Type   80.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "3    Temporal Type  120.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "4   Structured Out   80.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "5   Structured Out  120.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "6   Inference Cost   80.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "7   Inference Cost  120.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "8     Hardware Req   80.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "9     Hardware Req  120.0%  [Qwen2.5-VL, VideoLLaMA2, InternLM-XComposer2.5]   \n",
      "\n",
      "   Spearman_ρ  Top_Model_Changed  \n",
      "0    1.000000              False  \n",
      "1    1.000000              False  \n",
      "2    0.964286              False  \n",
      "3    1.000000              False  \n",
      "4    1.000000              False  \n",
      "5    1.000000              False  \n",
      "6    1.000000              False  \n",
      "7    1.000000              False  \n",
      "8    1.000000              False  \n",
      "9    1.000000              False  \n"
     ]
    }
   ],
   "source": [
    "sensitivity_df = sensitivity_analysis_weights(weights, data_matrix, model_names, is_benefit, 0.2)\n",
    "print(sensitivity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78acdb-1d45-4331-86f1-d51cb6d67575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
