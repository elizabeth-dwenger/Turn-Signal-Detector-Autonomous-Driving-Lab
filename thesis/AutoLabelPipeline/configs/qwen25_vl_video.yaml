# Configuration for Qwen2.5-VL (Video Mode)

experiment:
  name: "qwen25_vl_video_v1"
  output_dir: "results/qwen25_vl_video/"
  random_seed: 42
  description: "Qwen2.5-VL for turn signal detection - video mode (multi-image)"

data:
  input_csv: "data/tracking_data.csv"
  crop_base_dir: "/gpfs/space/projects/ml2024/"
  frame_base_dir: null
  max_sequences: null
  sequence_filter: null
  video_fps: 10

preprocessing:
  resize_resolution: [640, 480]
  normalize: true
  maintain_aspect_ratio: true
  padding_color: [0, 0, 0]
  max_sequence_length: null
  sequence_stride: 1

model:
  type: "qwen25_vl"
  inference_mode: "video"
  # Use local path 
  model_name_or_path: "/gpfs/helios/home/dwenger/models/huggingface/transformers/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5"
  # OR use HuggingFace identifier (will download if not cached):
  # model_name_or_path: "Qwen/Qwen2.5-VL-7B-Instruct"
  device: "cuda"
  batch_size: 1
  max_new_tokens: 1000
  temperature: 0.0
  top_p: 1.0
  do_sample: false
  prompt_template_path: "data/prompts/video_exp_05.txt"

  model_kwargs:
    trust_remote_code: true
    torch_dtype: "bfloat16"

postprocessing:
  temporal_smoothing_enabled: false
  smoothing_method: "mode"
  smoothing_window_size: 7
  min_signal_duration_frames: 3
  max_signal_duration_frames: null
  single_image: null

quality_control:
  random_sample_rate: 0.05
  stratified_sampling: true
  flag_both_signals: true
  flag_rapid_changes: true
  rapid_change_threshold: 3

output:
  formats: ["csv", "json"]
  include_raw_output: false
  save_visualizations: true
  visualization_sample_rate: 0.01
  visualization_output_dir: null
  export_review_queue: true
  review_queue_format: "json"

logging:
  level: "INFO"
  log_file: null
  console_output: true
  track_metrics: true
  show_progress_bar: true
  log_frequency: 10
